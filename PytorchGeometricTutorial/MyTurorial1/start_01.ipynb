{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ahahah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[3, 1], edge_index=[2, 3])\n",
      "Data has been valutated as: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "edge_index = torch.tensor([[0, 1, 1, 2],\n",
    "                           [1, 0, 2, 1]], dtype=torch.long)\n",
    "#edge_index = torch.tensor([[0, 1, 1],\n",
    "#                           [1, 0, 2]], dtype=torch.long)\n",
    "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "\n",
    "print(data)\n",
    "\n",
    "print(f\"Data has been valutated as: {data.validate(raise_on_error=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x found in data\n",
      "edge_index found in data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(data))\n",
    "for key, item in data:\n",
    "    print(f'{key} found in data')\n",
    "data.num_nodes\n",
    "\n",
    "data.num_edges\n",
    "data.num_node_features\n",
    "data.has_isolated_nodes()\n",
    "data.has_self_loops()\n",
    "data.is_directed()\n",
    "\n",
    "device = torch.device('cuda')\n",
    "data = data.to(device)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://www.chrsmrrs.com/graphkerneldatasets/ENZYMES.zip\n",
      "Extracting /tmp/ENZYMES/ENZYMES/ENZYMES.zip\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "6\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "\n",
    "dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES')\n",
    "print(len(dataset))\n",
    "print(dataset.num_classes)\n",
    "print(dataset.num_node_features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting dataset in train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = dataset.shuffle()\n",
    "# or \n",
    "# perm = torch.randperm(len(dataset))\n",
    "#dataset = dataset[perm]\n",
    "train_dataset = dataset[:540]\n",
    "test_dataset = dataset[540:]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset cora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lenght of the dataset is : 1\n",
      "Each node has 1433 features\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "dataset2 = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "\n",
    "print(f\"The lenght of the dataset is : {len(dataset2)}\")\n",
    "\n",
    "print(f\"Each node has {dataset2.num_node_features} features\")\n",
    "\n",
    "#data = dataset[0]\n",
    "#data.is_undirected()\n",
    "#dataTrain = data.train_mask.sum().item()\n",
    "#dataVal = data.val_mask.sum().item()\n",
    "#dataTest = data.test_mask.sum().item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(edge_index=[2, 4358], x=[1125, 21], y=[32], batch=[1125], ptr=[33])\n",
      "32\n",
      "DataBatch(edge_index=[2, 3480], x=[884, 21], y=[32], batch=[884], ptr=[33])\n",
      "32\n",
      "DataBatch(edge_index=[2, 3784], x=[956, 21], y=[32], batch=[956], ptr=[33])\n",
      "32\n",
      "DataBatch(edge_index=[2, 3898], x=[1001, 21], y=[32], batch=[1001], ptr=[33])\n",
      "32\n",
      "DataBatch(edge_index=[2, 4226], x=[1081, 21], y=[32], batch=[1081], ptr=[33])\n",
      "32\n",
      "DataBatch(edge_index=[2, 4536], x=[1203, 21], y=[32], batch=[1203], ptr=[33])\n",
      "32\n",
      "DataBatch(edge_index=[2, 3862], x=[1058, 21], y=[32], batch=[1058], ptr=[33])\n",
      "32\n",
      "DataBatch(edge_index=[2, 4008], x=[1057, 21], y=[32], batch=[1057], ptr=[33])\n",
      "32\n",
      "DataBatch(edge_index=[2, 3772], x=[967, 21], y=[32], batch=[967], ptr=[33])\n",
      "32\n",
      "DataBatch(edge_index=[2, 3892], x=[1093, 21], y=[32], batch=[1093], ptr=[33])\n",
      "32\n",
      "DataBatch(edge_index=[2, 3692], x=[990, 21], y=[32], batch=[990], ptr=[33])\n",
      "32\n",
      "DataBatch(edge_index=[2, 4248], x=[1070, 21], y=[32], batch=[1070], ptr=[33])\n",
      "32\n",
      "DataBatch(edge_index=[2, 4536], x=[1218, 21], y=[32], batch=[1218], ptr=[33])\n",
      "32\n",
      "DataBatch(edge_index=[2, 3858], x=[971, 21], y=[32], batch=[971], ptr=[33])\n",
      "32\n",
      "DataBatch(edge_index=[2, 3348], x=[875, 21], y=[32], batch=[875], ptr=[33])\n",
      "32\n",
      "DataBatch(edge_index=[2, 4022], x=[1082, 21], y=[32], batch=[1082], ptr=[33])\n",
      "32\n",
      "DataBatch(edge_index=[2, 4122], x=[1193, 21], y=[32], batch=[1193], ptr=[33])\n",
      "32\n",
      "DataBatch(edge_index=[2, 3904], x=[993, 21], y=[32], batch=[993], ptr=[33])\n",
      "32\n",
      "DataBatch(edge_index=[2, 3018], x=[763, 21], y=[24], batch=[763], ptr=[25])\n",
      "24\n",
      "DataBatch(edge_index=[2, 3920], x=[1029, 21], y=[32], batch=[1029], ptr=[33])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "DataBatch(edge_index=[2, 3946], x=[1043, 21], y=[32], batch=[1043], ptr=[33])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "DataBatch(edge_index=[2, 4560], x=[1194, 21], y=[32], batch=[1194], ptr=[33])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "DataBatch(edge_index=[2, 4174], x=[1130, 21], y=[32], batch=[1130], ptr=[33])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "DataBatch(edge_index=[2, 3744], x=[954, 21], y=[32], batch=[954], ptr=[33])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "DataBatch(edge_index=[2, 4188], x=[1036, 21], y=[32], batch=[1036], ptr=[33])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "DataBatch(edge_index=[2, 4560], x=[1192, 21], y=[32], batch=[1192], ptr=[33])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "DataBatch(edge_index=[2, 3320], x=[872, 21], y=[32], batch=[872], ptr=[33])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "DataBatch(edge_index=[2, 4050], x=[1052, 21], y=[32], batch=[1052], ptr=[33])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "DataBatch(edge_index=[2, 3654], x=[936, 21], y=[32], batch=[936], ptr=[33])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "DataBatch(edge_index=[2, 4354], x=[1081, 21], y=[32], batch=[1081], ptr=[33])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "DataBatch(edge_index=[2, 3968], x=[1069, 21], y=[32], batch=[1069], ptr=[33])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "DataBatch(edge_index=[2, 4114], x=[1059, 21], y=[32], batch=[1059], ptr=[33])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "DataBatch(edge_index=[2, 4158], x=[1092, 21], y=[32], batch=[1092], ptr=[33])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "DataBatch(edge_index=[2, 3922], x=[1122, 21], y=[32], batch=[1122], ptr=[33])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "DataBatch(edge_index=[2, 3448], x=[907, 21], y=[32], batch=[907], ptr=[33])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "DataBatch(edge_index=[2, 3694], x=[1012, 21], y=[32], batch=[1012], ptr=[33])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "DataBatch(edge_index=[2, 3632], x=[925, 21], y=[32], batch=[925], ptr=[33])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "DataBatch(edge_index=[2, 3158], x=[875, 21], y=[24], batch=[875], ptr=[25])\n",
      "24\n",
      "torch.Size([24, 21])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import scatter\n",
    "\n",
    "dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES', use_node_attr=True)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "for batch in loader:\n",
    "    print(batch)\n",
    "    print(batch.num_graphs)\n",
    "\n",
    "for data in loader:\n",
    "    print(data)\n",
    "    print(data.num_graphs)\n",
    "    x = scatter(data.x, data.batch, dim=0, reduce='mean')\n",
    "    print(x.size())\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transform\n",
    "\n",
    "Transforms are a common way in torchvision to transform images and perform augmentation. PyG comes with its own transforms, which expect a Data object as input and return a new transformed Data object. Transforms can be chained together using torch_geometric.transforms.Compose and are applied before saving a processed dataset on disk (pre_transform) or before accessing a graph in a dataset (transform).\n",
    "\n",
    "Letâ€™s look at an example, where we apply transforms on the ShapeNet dataset (containing 17,000 3D shape point clouds and per point labels from 16 shape categories)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://shapenet.cs.stanford.edu/media/shapenetcore_partanno_segmentation_benchmark_v0_normal.zip\n",
      "Extracting /tmp/ShapeNet/shapenetcore_partanno_segmentation_benchmark_v0_normal.zip\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard dataset Data(x=[2518, 3], y=[2518], pos=[2518, 3], category=[1])\n",
      "Augmented dataset Data(x=[2518, 3], y=[2518], pos=[2518, 3], category=[1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "/Users/beppe2hd/miniforge3/envs/GNNtestEnv/lib/python3.10/site-packages/torch_geometric/data/dataset.py:209: UserWarning: The `pre_transform` argument differs from the one used in the pre-processed version of this dataset. If you want to make use of another pre-processing technique, make sure to delete '/tmp/ShapeNet/processed' first\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import ShapeNet\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "dataset = ShapeNet(root='/tmp/ShapeNet', categories=['Airplane'])\n",
    "\n",
    "print(f\"Standard dataset {dataset[0]}\")\n",
    "\n",
    "dataset = ShapeNet(root='/tmp/ShapeNet', categories=['Airplane'],\n",
    "                    pre_transform=T.KNNGraph(k=6))\n",
    "\n",
    "print(f\"Augmented dataset {dataset[0]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Methods on Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cora()\n",
      "First model\n",
      "Accuracy: 0.8050\n",
      "Second model\n",
      "Accuracy: 0.7850\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "class GCNExtra(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, 6)\n",
    "        self.conv3 = GCNConv(6, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "\n",
    "        return x\n",
    "    \n",
    "print(dataset)\n",
    "    \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(\"First model\")\n",
    "\n",
    "model = GCN().to(device)\n",
    "data = dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "model.eval()\n",
    "pred = model(data).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "print(f'Accuracy: {acc:.4f}')\n",
    "\n",
    "\n",
    "print(\"Second model\")\n",
    "\n",
    "model = GCNExtra().to(device)\n",
    "data = dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "model.eval()\n",
    "pred = model(data).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNNtestEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
